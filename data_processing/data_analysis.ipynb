{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import uuid\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['8岁女孩下体受伤案，究竟有无老师唆使？.txt',\n",
       " '深圳GDP首次超越香港，成粤港澳大湾区经济总量第一城.txt',\n",
       " '拆除“削山别墅”，更得打击违建者嚣张气焰.txt',\n",
       " '“投币大军”再增一员这“病”如何治.txt',\n",
       " '山西太原明星市长耿彦波卸任，曾被称现实版李达康.txt',\n",
       " '权健公司束某某等16人被依法批准逮捕.txt',\n",
       " '起底城市绿化中的奢靡之风：贫困县斥资200多万种银杏.txt',\n",
       " '从警35年的副市长退休三年被挖出，曾被举报向黑老大赠送字画.txt',\n",
       " '百名婴幼儿口服过期疫苗，责任心去哪了？.txt',\n",
       " '陕西省委原书记赵正永涉严重违纪违法接受纪律审查和监察调查.txt',\n",
       " '呼和浩特发布大学毕业生“半价购房”新政，专家：力度大或作用有限.txt',\n",
       " '辽宁教育厅回应“等8年突然被取消高考资格”：改革需要.txt',\n",
       " '未婚女孩6年做17次流产，子宫薄如纸！医生都看不下去了…….txt',\n",
       " '龙永图：多向美国进口是一种进步 符合贸易政策调整方向.txt',\n",
       " '加总理称中国随意作死刑判决，中国外交部：加方缺乏法治精神.txt',\n",
       " '捷克总理：华为威胁国家安全？没证据.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/sohu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/sohu/8岁女孩下体受伤案，究竟有无老师唆使？.txt',\n",
       " '../data/sohu/深圳GDP首次超越香港，成粤港澳大湾区经济总量第一城.txt',\n",
       " '../data/sohu/拆除“削山别墅”，更得打击违建者嚣张气焰.txt',\n",
       " '../data/sohu/“投币大军”再增一员这“病”如何治.txt',\n",
       " '../data/sohu/山西太原明星市长耿彦波卸任，曾被称现实版李达康.txt',\n",
       " '../data/sohu/权健公司束某某等16人被依法批准逮捕.txt',\n",
       " '../data/sohu/起底城市绿化中的奢靡之风：贫困县斥资200多万种银杏.txt',\n",
       " '../data/sohu/从警35年的副市长退休三年被挖出，曾被举报向黑老大赠送字画.txt',\n",
       " '../data/sohu/百名婴幼儿口服过期疫苗，责任心去哪了？.txt',\n",
       " '../data/sohu/陕西省委原书记赵正永涉严重违纪违法接受纪律审查和监察调查.txt',\n",
       " '../data/sohu/呼和浩特发布大学毕业生“半价购房”新政，专家：力度大或作用有限.txt',\n",
       " '../data/sohu/辽宁教育厅回应“等8年突然被取消高考资格”：改革需要.txt',\n",
       " '../data/sohu/未婚女孩6年做17次流产，子宫薄如纸！医生都看不下去了…….txt',\n",
       " '../data/sohu/龙永图：多向美国进口是一种进步 符合贸易政策调整方向.txt',\n",
       " '../data/sohu/加总理称中国随意作死刑判决，中国外交部：加方缺乏法治精神.txt',\n",
       " '../data/sohu/捷克总理：华为威胁国家安全？没证据.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_list = ['../data/sohu/' + item for item in os.listdir('../data/sohu')]\n",
    "file_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32959\n",
      "32959\n"
     ]
    }
   ],
   "source": [
    "# 统计搜狐评论数量\n",
    "comment_num = 0\n",
    "sohu_comment_list = []\n",
    "for item in file_path_list:\n",
    "    with open(item, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            sample = {\n",
    "                    'uid': str(uuid.uuid1()),\n",
    "                    'comment': line,\n",
    "                    'line': line,\n",
    "            }\n",
    "            sohu_comment_list.append(sample)\n",
    "        comment_num += len(lines)\n",
    "print(comment_num)\n",
    "print(len(sohu_comment_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/sohu_test_v0.json', 'w', encoding='utf-8') as f:\n",
    "#     for item in sohu_comment_list:\n",
    "#         write_str = json.dumps(item, ensure_ascii=False)\n",
    "#         f.write(write_str)\n",
    "#         f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': '0fd9d1b6-04a5-11ed-95f9-a683e78cc882',\n",
       " 'comment': '看人家没有能出头的人，就这么欺负，简直太黑暗了，跟红楼梦里薛蟠打死人的情节太像了，堂堂法治社会，怎么能出这么黑暗的事！',\n",
       " 'line': '看人家没有能出头的人，就这么欺负，简直太黑暗了，跟红楼梦里薛蟠打死人的情节太像了，堂堂法治社会，怎么能出这么黑暗的事！'}"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sohu_comment_list[129]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120000\n"
     ]
    }
   ],
   "source": [
    "# 统计微博评论数量\n",
    "pos_file_path = '../data/pos60000.txt'\n",
    "neg_file_path = '../data/neg60000.txt'\n",
    "\n",
    "weibo_path_list = [pos_file_path, neg_file_path]\n",
    "\n",
    "comment_num = 0\n",
    "for item in weibo_path_list:\n",
    "    with open(item, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        comment_num += len(lines)\n",
    "print(comment_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 以搜狐评论不带标签数据 32959 为测试集\n",
    "### 以微博评论具有标签数据 120000 位训练集 + 补充开源的中文情绪分类数据\n",
    "### 微博评论数据存在问题\n",
    "* 怀疑训练数据的标签是根据 emoji 表情自动标准的，标签准确率需要评估\n",
    "* 带有很多转载，\\@ 符合，用户昵称本身等，对整个评论情绪识别干扰，需要过滤处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dd1eed6de345859f600ab64f0ffabd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d5166a990f46a98d335cf5034be592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=60000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "120000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weibo_comment_list = []\n",
    "zhuan_zai_reg = re.compile(r'\\//[\\s]*@.*?[\\:\\：]{1}')\n",
    "for item in weibo_path_list:\n",
    "    with open(item, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in tqdm(lines):\n",
    "            line = line.strip()\n",
    "            comment_list = re.split(zhuan_zai_reg, line)\n",
    "            if item == pos_file_path:\n",
    "                sample = {\n",
    "                    'uid': str(uuid.uuid1()),\n",
    "                    'comment': ''.join(comment_list).lstrip().rstrip(),\n",
    "                    'line': line,\n",
    "                    'sentiment_label': 1\n",
    "                }\n",
    "                weibo_comment_list.append(sample)\n",
    "            else:\n",
    "                sample = {\n",
    "                    'uid': str(uuid.uuid1()),\n",
    "                    'comment': ''.join(comment_list).lstrip().rstrip(),\n",
    "                    'line': line,\n",
    "                    'sentiment_label': 0\n",
    "                }\n",
    "                weibo_comment_list.append(sample)\n",
    "                    \n",
    "len(weibo_comment_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': '92a34ad2-044b-11ed-95f9-a683e78cc882',\n",
       " 'comment': '哈，下次我赶着一头驴，唱着“我的故乡在远方”去旅行。[爱你]',\n",
       " 'line': '哈，下次我赶着一头驴，唱着“我的故乡在远方”去旅行。[爱你]',\n",
       " 'sentiment_label': 1}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_index = random.randint(0, 119999)\n",
    "random.shuffle(weibo_comment_list)\n",
    "weibo_comment_list[sample_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,\n",
       " {'uid': '92b9f930-044b-11ed-95f9-a683e78cc882',\n",
       "  'comment': '[偷笑],办法满好的，就是接着只好趴着睡觉，枕头上要挖个洞[哈哈]',\n",
       "  'line': '[偷笑],办法满好的，就是接着只好趴着睡觉，枕头上要挖个洞[哈哈]',\n",
       "  'sentiment_label': 1})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 随机抽样 100 条，得到训练集精度\n",
    "\n",
    "weibo_comment_list_demo = random.sample(weibo_comment_list, 100)\n",
    "len(weibo_comment_list_demo), weibo_comment_list_demo[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n"
     ]
    }
   ],
   "source": [
    "# 将处理好的训练集写成 json 文件\n",
    "# 将抽样数据 100 条整成 excel\n",
    "\n",
    "# with open('../data/weibo_train_v0_by_emoji.json', 'w', encoding='utf-8') as f:\n",
    "#     for item in weibo_comment_list:\n",
    "#         write_str = json.dumps(item, ensure_ascii=False)\n",
    "#         f.write(write_str)\n",
    "#         f.write('\\n')\n",
    "\n",
    "# new_df = pd.DataFrame()\n",
    "# new_df['uid'] = [item['uid'] for item in weibo_comment_list_demo]\n",
    "# new_df['comment'] = [item['comment'] for item in weibo_comment_list_demo]\n",
    "# new_df['line'] = [item['line'] for item in weibo_comment_list_demo]\n",
    "# new_df['sentiment_label'] = [item['sentiment_label'] for item in weibo_comment_list_demo]\n",
    "# print(new_df.shape)\n",
    "# new_df.to_excel('../data/weibo_train_v0_by_emoji_sample_100.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经过人工验证 sentiment_label ，标签准确率为 93%\n",
    "# 可以搞第一版模型了\n",
    "# baseline 模型 —— bert"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
